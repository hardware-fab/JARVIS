{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from matplotlib import pyplot as plt\n",
    "from sca_utils.metrics import dumpMetrics\n",
    "from attack.CNN.create_dataset import createDataset, plotTargetStatistics, printDatasetInfo\n",
    "from attack.CNN.train import train\n",
    "from attack.CNN.attack import guessingMetrics, getModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2025)\n",
    "pl.seed_everything(2025, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset for training the CNN. The dataset is split into __training__, __validation__ and __test__ subset.\n",
    "\n",
    "Each subset consists into three .npy files:\n",
    "- _windows_: it contains the side-channel traces accordingly preprocessed.\n",
    "- _targets_: it contains the target labels for trainig the CNN. Each label has 16 fields, one for each key byte.\n",
    "- _meta_: it contains additional metadata to proper test the CNN, i.e., plaintext and key, for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_folder =  \"</path/to/traces/folder/>\"\n",
    "dataset_folder = \"</path/to/out/dataset/folder/>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trace_files = [trace_folder + f for f in os.listdir(trace_folder)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function _createDataset_ has a few optional parameters:\n",
    "- `window`: Choose the window to use to extract the traces. If empty the window will be the whole trace (default is []).\n",
    "- `filter`: Apply a highpass filter to traces as preprocessing (default is True).\n",
    "- `aggregate_n_samples`: Determine how many consecutive samples to average together as preprocessing (default is 1).\n",
    "- `std`: Flag to normalize the traces feature-wise as preprocessing (default is False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDataset(all_trace_files, dataset_folder)\n",
    "plotTargetStatistics(dataset_folder)\n",
    "printDatasetInfo(dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each CNN is configure thanks to a YALM configuration file.  \n",
    "You can set different module hyper-parameters as well as the dataset, the logger, and the experiment configurations.  \n",
    "Default configuration are in `configs` directory, both for Neputune logger and for the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_folder = \"attack/CNN/configs/cnn_exp_v1\" #\"/path/to/experiment/config/folder/\"\n",
    "gpu = 0 # 0 if you want to use the first GPU, 1 if you want to use the second GPU, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(config_folder, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### Compute Guessing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_folder = \"</path/to/attack/traces/folder/>\"\n",
    "result_folder = \"</path/to/save/results/folder/>\" \n",
    "SID = \"<Neptun ID>\"\n",
    "\n",
    "trace_files = [attack_folder + f for f in os.listdir(attack_folder)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the trained CNN starting from Neptune SID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = getModule(SID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute, save and plot metrics. In folder `result_folder` there is a .txt summary of the principal side-channel metrics.  \n",
    "Function _guessingMetrics_ has a few optional parameters to __set the same as during the module training__:\n",
    "- `target_byte`: Determine on which intermediate byte profile the Template (default is byte 0).\n",
    "- `window`: Choose the window to use to extract the traces. If empty the window will be the whole trace (default is []).\n",
    "- `filter`: Apply a highpass filter to traces as preprocessing (default is True).\n",
    "- `aggregate_n_samples`: Determine how many consecutive samples to average together as preprocessing (default is 1).\n",
    "- `std`: Flag to normalize the traces feature-wise as preprocessing (default is False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge, gd, ranks = guessingMetrics(trace_files, module)\n",
    "print(f\"Guessing distance: {gd}, Guessing entropy: {ge}\")\n",
    "\n",
    "# Save results\n",
    "dumpMetrics(result_folder, gd, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.mean(ranks, axis=0))\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sca-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
